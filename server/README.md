ğŸ§  Gen AI Analyst â€“ Debate Orchestrator

This project is a FastAPI + MongoDB backend that allows you to upload documents, extract text, and orchestrate structured debates between AI agents.
It supports ingestion of PDF, DOCX, PPTX, TXT, and images, stores them in MongoDB, and provides endpoints to simulate debates over extracted content.

ğŸ“‚ Project Structure
server/
â”‚â”€â”€ app/
â”‚   â”œâ”€â”€ main.py            # FastAPI entrypoint
â”‚   â”œâ”€â”€ config.py          # Environment & settings
â”‚   â”œâ”€â”€ db.py              # MongoDB Beanie setup
â”‚   â”œâ”€â”€ models.py          # MongoDB models
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”œâ”€â”€ upload.py      # File ingestion
â”‚   â”‚   â”œâ”€â”€ documents.py   # Document retrieval
â”‚   â”‚   â””â”€â”€ debate.py      # Debate orchestration
â”‚   â””â”€â”€ services/
â”‚       â”œâ”€â”€ storage.py     # File storage utils
â”‚       â”œâ”€â”€ parsers.py     # PDF/DOCX/PPTX/TXT/Image parsers
â”‚       â”œâ”€â”€ orchestrator.py# Debate flow orchestration
â”‚       â””â”€â”€ llm_client.py  # LLM API client (OpenAI / Ollama)
â”‚
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ .env.example
â”‚â”€â”€ README.md

âš™ï¸ Setup
1. Clone repo & install dependencies
git clone <your-repo-url>
cd backend
python -m venv venv
source venv/bin/activate   # On Windows: venv\Scripts\activate
pip install -r requirements.txt

2. Environment variables

Copy .env.example â†’ .env and update:

MONGO_URI=mongodb://localhost:27017/debate_ai
OPENAI_API_KEY=your_api_key_here   # or leave blank if using Ollama

3. Start server
uvicorn app.main:app --reload


Server will run at: http://127.0.0.1:8000

ğŸš€ API Usage
ğŸ“¤ 1. File Upload

POST /upload/

Form-data: file (required), user_id (optional)

Response:

{
  "id": "6489a23abc123",
  "status": "processed"
}

ğŸ“¥ 2. Get All Files

GET /documents/

ğŸ“„ 3. Get Document by ID

GET /documents/{document_id}

ğŸ—£ï¸ 4. Start Debate Session

POST /debate/start?topic=StartupX&document_id={doc_id}

Response:

{
  "id": "66f0f352f10f0d2a4e8a5678"
}

ğŸ”„ 5. Run Next Debate Round

POST /debate/{session_id}/next

Response:

{
  "agent": "Pro",
  "message": "I believe StartupX has strong potential..."
}

ğŸ“œ 6. Get Debate Transcript

GET /debate/{session_id}/transcript

Response:

{
  "messages": [
    {"agent": "Pro", "message": "..."},
    {"agent": "Con", "message": "..."}
  ]
}

ğŸ› ï¸ Notes

By default, this project uses OpenAI API. If you donâ€™t have credits, switch to Ollama (local model).

All extracted texts and debates are stored in MongoDB.